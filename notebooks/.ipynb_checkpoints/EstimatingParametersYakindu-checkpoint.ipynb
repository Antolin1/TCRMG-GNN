{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "sys.path.append('../python/')\n",
    "from json2graph import jsonFile2graph\n",
    "from graphUtils import plot_graph\n",
    "from statsUtils import whichFitsBetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading $R_{II}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "files = glob.glob(\"../realGraphs/Yakindu/R2/*.json\")\n",
    "\n",
    "Gs = []\n",
    "for file in files:\n",
    "    Gs.append(jsonFile2graph(file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random EMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rule in RandomEMF, depending on the type of rule, we estimate its parameters. More concretely, for shapes we use the function `whichFitsBetter` that selects the best distribuntion by using maximum likeihood. For priorities in alternative rules, the procedure described in the paper is done and it is based on counting each different alternative in the set $R_{II}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of regions per statechart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "Root : Statechart ->\n",
    "\t\tregions += RegionsStatechart#Distribution(parameters)\n",
    "\t; \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nums = []\n",
    "for G in Gs:\n",
    "    nums.append(G.out_degree(0))\n",
    "bins = np.arange(1, 3, 0.5)\n",
    "plt.hist(nums, bins = bins, alpha=0.5, density = False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of regions per state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\tRState (Region r) : State ->\n",
    "\t\tregions += RegionsState#Distribution(parameters)\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberSubvertex = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='State':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'regions'):\n",
    "                        cont = cont + 1\n",
    "            numberSubvertex.append(cont)\n",
    "            \n",
    "bins = np.arange(0, 10, 1)\n",
    "plt.hist(numberSubvertex, bins = bins, alpha=0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = whichFitsBetter(numberSubvertex)\n",
    "print(best)\n",
    "lambda_= best['params']\n",
    "#print(r,p)\n",
    "#print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import nbinom\n",
    "from scipy.stats import poisson\n",
    "\n",
    "\n",
    "t = np.arange(0, 10, 1)\n",
    "#d = nbinom.pmf(t, 1, p, 0)\n",
    "d = poisson.pmf(t,lambda_)\n",
    "#np.exp(-np.mean(numberClassifiers))*np.power(np.mean(numberClassifiers), t)/factorial(t)\n",
    "plt.hist(numberSubvertex, bins = bins, alpha=0.5, density = True)\n",
    "plt.plot(t, d, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\talter Vertices (Region r) : Vertex ->\n",
    "\t\t RPseudoState(r)#a | RRegularState(r)#b\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0]\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'FinalState'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'State'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'Synchronization'):\n",
    "            p[1] = p[1] + 1\n",
    "        if (G.nodes[n]['type'] == 'Choice'):\n",
    "            p[1] = p[1] + 1\n",
    "        if (G.nodes[n]['type'] == 'Exit'):\n",
    "            p[1] = p[1] + 1\n",
    "        if (G.nodes[n]['type'] == 'Entry'):\n",
    "            p[1] = p[1] + 1\n",
    "    p = np.array(p)\n",
    "    ps.append(p/np.sum(p))\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/np.min(np.mean(ps, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\talter RRegularState (Region r) : RegularState ->\n",
    "\t\tRFinal#a | RState(r)#b \n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0]\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'FinalState'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'State'):\n",
    "            p[1] = p[1] + 1\n",
    "    p = np.array(p)\n",
    "    ps.append(p/np.sum(p))\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/np.min(np.mean(ps, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\talter RPseudoState(Region r) : Pseudostate ->\n",
    "\t\t RTypeSynchronization(r)#a  | RTypeExit#b | RTypeChoice(r)#c\n",
    "\t\t | if (r.vertices.filter[it instanceof Entry].size == 0 \n",
    "\t\t \t&& r.vertices.size > 0 \n",
    "\t\t ) RTypeEntry(r)#d\n",
    "\t;\n",
    "\t\n",
    "```\n",
    "\n",
    "We want to estimate `a`, `b`, `c` and `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0, 0, 0]\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'Synchronization'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'Choice'):\n",
    "            p[1] = p[1] + 1\n",
    "        if (G.nodes[n]['type'] == 'Exit'):\n",
    "            p[2] = p[2] + 1\n",
    "        if (G.nodes[n]['type'] == 'Entry'):\n",
    "            p[3] = p[3] + 1\n",
    "    p = np.array(p)\n",
    "    ps.append(p/np.sum(p))\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/np.min(np.mean(ps, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transitions per state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\tRState (Region r) : State ->\n",
    "\t\toutgoingTransitions += RTransition(self,r)#Distribution(parameters)\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberTransitions = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'State'):\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'outgoingTransitions'):\n",
    "                        cont = cont + 1\n",
    "            numberTransitions.append(cont)\n",
    "bins = np.arange(0, 10, 1)\n",
    "plt.hist(numberTransitions, bins = bins, alpha=0.5, density = True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = whichFitsBetter(numberTransitions)['params']\n",
    "print(lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import poisson\n",
    "\n",
    "\n",
    "t = np.arange(0, 10, 1)\n",
    "d = poisson.pmf(t, lambda_, 0)\n",
    "\n",
    "#np.exp(-np.mean(numberClassifiers))*np.power(np.mean(numberClassifiers), t)/factorial(t)\n",
    "plt.hist(numberTransitions, bins = bins, alpha=0.5, density = True)\n",
    "plt.plot(t, d, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\tRTypeSynchronization (Region r) : Synchronization ->\n",
    "\t\toutgoingTransitions += RTransition(self,r)#Distribution(parameters)\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberTransitions = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'Synchronization'):\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'outgoingTransitions'):\n",
    "                        cont = cont + 1\n",
    "            numberTransitions.append(cont)\n",
    "bins = np.arange(0, 3, 0.5)\n",
    "plt.hist(numberTransitions, bins = bins, alpha=0.5, density = False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberTransitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\tRTypeChoice (Region r) : Choice->\n",
    "\t\toutgoingTransitions += RTransition(self,r)#Distribution(parameters)\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberTransitions = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'Choice'):\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'outgoingTransitions'):\n",
    "                        cont = cont + 1\n",
    "            numberTransitions.append(cont)\n",
    "bins = np.arange(0, 10, 0.5)\n",
    "plt.hist(numberTransitions, bins = bins, alpha=0.5, density = False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberTransitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number vertex per region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statechart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\tRegionsStatechart : Region ->\n",
    "\t\tvertices += Vertices(self)#Distribution(parameters)\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromStateChart(G,n):\n",
    "    for m in G:\n",
    "        if (G.nodes[m]['type'] == 'Statechart'):\n",
    "            try:\n",
    "                for e in G[m][n]:\n",
    "                    if (G[m][n][e]['type'] == 'regions'):\n",
    "                        return True\n",
    "            except:\n",
    "                return False\n",
    "    return False\n",
    "\n",
    "numberVert = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'Region') and (fromStateChart(G,n)):\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'vertices'):\n",
    "                        cont = cont + 1\n",
    "            numberVert.append(cont)\n",
    "bins = np.arange(0, 10, 1)\n",
    "plt.hist(numberVert, bins = bins, alpha=0.5, density = True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(whichFitsBetter(numberVert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "```\n",
    "\tRegionsState : Region ->\n",
    "\t\tvertices += Vertices(self)#Distribution(parameters)\n",
    "\t;\n",
    "\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromState(G,n):\n",
    "    for m in G:\n",
    "        if (G.nodes[m]['type'] == 'State'):\n",
    "            try:\n",
    "                for e in G[m][n]:\n",
    "                    if (G[m][n][e]['type'] == 'regions'):\n",
    "                        return True\n",
    "            except:\n",
    "                return False\n",
    "    return False\n",
    "\n",
    "numberVert = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'Region') and (fromState(G,n)):\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'vertices'):\n",
    "                        cont = cont + 1\n",
    "            numberVert.append(cont)\n",
    "bins = np.arange(0, 10, 1)\n",
    "plt.hist(numberVert, bins = bins, alpha=0.5, density = True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberVert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIATRA and ALLOY, estimating the scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For VIATRA and ALLOY, the distribution over the objects (i.e., $P(o)$) needs to be approximated. First, we calculate $\\{o_1,\\dots,o_n\\}$ by counting the number of objects of each model in $R_{II}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the KDE function:\n",
    "\n",
    "$$\\hat{f}_{h,K}(o)=\\frac{1}{nh}\\sum_{i=1}^nK\\left(\\frac{o-o_i}{h}\\right).$$\n",
    "\n",
    "Where $K \\in \\{\\text{gaussian, tophat}\\}$ and $h\\in \\texttt{np.logspace(-1, -1, 20)}$. $K$ and $h$ are fixed using crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "numberObjects = [[len([n for n in G])] for G in Gs]\n",
    "\n",
    "params = {'bandwidth': np.logspace(-1, 1, 20),\n",
    "         'kernel':['gaussian', 'tophat']}\n",
    "grid = GridSearchCV(KernelDensity(), params)\n",
    "grid.fit(np.array(numberObjects))\n",
    "print(\"best bandwidth: {0}\".format(grid.best_estimator_.bandwidth))\n",
    "print(\"best kernel: {0}\".format(grid.best_estimator_.kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the histogram samples are close to the original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kde = grid.best_estimator_\n",
    "new_data = kde.sample(250, random_state=0)\n",
    "new_data = new_data.reshape(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "size_bin=2\n",
    "bins = np.arange(0, 30, size_bin)\n",
    "numberObjects = [len([n for n in G]) for G in Gs]\n",
    "hist = plt.hist(numberObjects, bins = bins, alpha=0.5,density=True)\n",
    "plt.hist(new_data, bins = bins, alpha=0.5,density=True)\n",
    "probs = hist[0]\n",
    "probs = (probs/np.sum(probs))\n",
    "objs = hist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the config files for VIATRA and ALLOY. These files are already provided together with the final and generated models. Therefore, you should not execute these code snippets.\n",
    "\n",
    "**Note**: For Alloy we generate more samples (434) since the generator fails more when it looks for a solution to the logic problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import random\n",
    "i = 0\n",
    "for s in new_data:\n",
    "    with open('../configurationFiles/Yakindu/model.vsconfig', 'r') as file:\n",
    "        data = file.read()\n",
    "    x = data.replace(\"#node += 29..31\", \"#node += \"+str(int(s)))\n",
    "    x = x.replace(\"debug =\\t\\t\\t\\\"outputs/debug\\\"\",\"debug =\\t\\t\\t\\\"outputs\"+str(i)+\"/debug\\\"\")\n",
    "    x = x.replace(\"log =\\t\\t\\t\\\"outputs/log.txt\\\"\",\"log =\\t\\t\\t\\\"outputs\"+str(i)+\"/log.txt\\\"\")\n",
    "    x = x.replace(\"output =\\t\\t\\\"outputs/models\\\"\",\"output =\\t\\t\\\"outputs\"+str(i)+\"/models\\\"\")\n",
    "    x = x.replace(\"runs = 400\",\"runs = 1\")\n",
    "    with open(\"../configurationFiles/Yakindu/VIATRA/yakinduGen\"+str(i)+\".vsconfig\", \"w\") as text_file:\n",
    "        text_file.write(x)\n",
    "        i = i + 1\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "new_data2 = kde.sample(184, random_state=1)\n",
    "new_data2 = new_data2.reshape(-1)\n",
    "new_data_alloy = np.hstack((new_data,new_data2))\n",
    "i = 0\n",
    "for s in new_data_alloy:\n",
    "    with open('../configurationFiles/Yakindu/modelAlloy.vsconfig', 'r') as file:\n",
    "        data = file.read()\n",
    "    x = data.replace(\"#node += 29..31\", \"#node += \"+str(int(s)))\n",
    "    x = x.replace(\"debug =\\t\\t\\t\\\"outputs/debug\\\"\",\"debug =\\t\\t\\t\\\"outputs\"+str(i)+\"/debug\\\"\")\n",
    "    x = x.replace(\"log =\\t\\t\\t\\\"outputs/log.txt\\\"\",\"log =\\t\\t\\t\\\"outputs\"+str(i)+\"/log.txt\\\"\")\n",
    "    x = x.replace(\"output =\\t\\t\\\"outputs/models\\\"\",\"output =\\t\\t\\\"outputs\"+str(i)+\"/models\\\"\")\n",
    "    x = x.replace(\"ViatraSolver\", \"AlloySolver\")\n",
    "    with open(\"../configurationFiles/Yakindu/ALLOY/yakinduGen\"+str(i)+\".vsconfig\", \"w\") as text_file:\n",
    "        text_file.write(x)\n",
    "        i = i + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do thy same as the previous section but considering pairs $(o,d)$ where $o$ is the number of objects and $d$ is the average out degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_objects = [np.mean([G.out_degree(n) for n in G]) for G in Gs]\n",
    "objects_deg = np.array(list(zip([n for [n] in numberObjects],deg_objects)))\n",
    "objects_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bandwidth': np.logspace(-1, 1, 20),\n",
    "         'kernel':['gaussian', 'tophat']}\n",
    "grid2 = GridSearchCV(KernelDensity(), params)\n",
    "grid2.fit(objects_deg)\n",
    "print(\"best bandwidth: {0}\".format(grid2.best_estimator_.bandwidth))\n",
    "print(\"best kernel: {0}\".format(grid2.best_estimator_.kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde2 = grid2.best_estimator_\n",
    "new_data2 = kde2.sample(184 * 2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the new data generated (i.e., new pairs $(o,d)$), we call the RANDOM generator in order to generate the models. Doing something like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import random\n",
    "import subprocess\n",
    "i = 0\n",
    "for s in new_data2:\n",
    "    subprocess.call(['java', '-jar', 'path to jar of the generator', \n",
    "                     '-m','path to metamodel',\n",
    "                    '-f','-n','1','-s',str(s[0]),'-d',str(s[1]),'-o',\n",
    "                     'path to output folder',\n",
    "                    '-e',str(i)])\n",
    "    i = i + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated models used to report the results in the paper are already provided."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
