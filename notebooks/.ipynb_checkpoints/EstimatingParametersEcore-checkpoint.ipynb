{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "sys.path.append('../python/')\n",
    "from json2graph import jsonFile2graph\n",
    "from graphUtils import plot_graph\n",
    "from statsUtils import whichFitsBetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading $R_{II}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "files = glob.glob(\"../realGraphs/Ecore/R2/*.json\")\n",
    "\n",
    "Gs = []\n",
    "for file in files:\n",
    "    Gs.append(jsonFile2graph(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomEMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rule in RandomEMF, depending on the type of rule, we estimate its parameters. More concretely, for shapes we use the function `whichFitsBetter` that selects the best distribuntion by using maximum likeihood. For priorities in alternative rules, the procedure described in the paper is done and it is based on counting each different alternative in the set $R_{II}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Package: EPackage ->\n",
    "    eClassifiers += Classifier#Distribution(parameters);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def isClassifier(tp):\n",
    "    if tp == 'EClass':\n",
    "        return True\n",
    "    if tp == 'EDataType':\n",
    "        return True\n",
    "    if tp == 'EEnum':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "bins = np.arange(0, 200, 5)\n",
    "numberClassifiers = [len([n for n in G if isClassifier(G.nodes[n]['type'])]) for G in Gs]\n",
    "plt.hist(numberClassifiers, bins = bins, alpha=0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberClassifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import nbinom\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "t = np.arange(0, 200, 1)\n",
    "d = nbinom.pmf(t, 1.0, 0.02159, 0)\n",
    "\n",
    "#np.exp(-np.mean(numberClassifiers))*np.power(np.mean(numberClassifiers), t)/factorial(t)\n",
    "f = plt.figure()\n",
    "plt.hist(numberClassifiers, bins = bins, alpha=0.5, density = True)\n",
    "plt.plot(t, d, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportions of classifiers that a package has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "alter Classifier : EClassifier ->\n",
    "  \tEnum#a | DataType#b |Class#c\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0, 0]\n",
    "    for n in G[0]:\n",
    "        if (G.nodes[n]['type'] == 'EClass'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'EDataType'):\n",
    "            p[1] = p[1] + 1\n",
    "        if (G.nodes[n]['type'] == 'EEnum'):\n",
    "            p[2] = p[2] + 1\n",
    "    p = np.array(p)\n",
    "    ps.append(p/np.sum(p))\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/0.03663906)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of eliterals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Enum : EEnum ->\n",
    "  \teLiterals += Literal#Distribution(parameters);\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEliterals = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EEnum':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eLiterals'):\n",
    "                        cont = cont + 1\n",
    "            numberEliterals.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 50, 1)\n",
    "plt.hist(numberEliterals, bins = bins, alpha=0.5, density = True)\n",
    "\n",
    "print('mean',np.mean(numberEliterals))\n",
    "print('var',np.var(numberEliterals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberEliterals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, 50, 1)\n",
    "d = nbinom.pmf(t, 1, 0.1349, 0)\n",
    "\n",
    "#np.exp(-np.mean(numberClassifiers))*np.power(np.mean(numberClassifiers), t)/factorial(t)\n",
    "plt.hist(numberEliterals, bins = bins, alpha=0.5, density = True)\n",
    "plt.plot(t, d, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Structural Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Class: EClass ->\n",
    "    eStructuralFeatures += Feature(self)#Distribution(parameters);\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberStrctFeat= []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EClass':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eStructuralFeatures'):\n",
    "                        cont = cont + 1\n",
    "            numberStrctFeat.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberStrctFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 50, 1)\n",
    "plt.hist(numberStrctFeat, bins = bins, alpha=0.5, density = True)\n",
    "\n",
    "print('mean',np.mean(numberStrctFeat))\n",
    "print('var',np.var(numberStrctFeat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuperTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Class: EClass ->\n",
    "    eSuperTypes +=  Uniform(model.EClassifiers.filter[\n",
    "      it instanceof org.eclipse.emf.ecore.EClass\n",
    "    ].filter[!this.self.EAllSuperTypes.contains(it)].map[it as org.eclipse.emf.ecore.EClass])#Distribution(parameters);\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superTypes= []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EClass':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eSuperTypes'):\n",
    "                        cont = cont + 1\n",
    "                superTypes.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(superTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EAttributes vs EReferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "alter Feature (EClass c): EStructuralFeature ->  \n",
    "     if (model.EClassifiers.filter[it instanceof EDataType].size > 0) Attribute#a |if (model.EClassifiers.filter[it instanceof org.eclipse.emf.ecore.EClass].size > 0)\n",
    "     Reference(c)#b\n",
    "  ;\n",
    "```\n",
    "\n",
    "Estimating `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0]\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'EAttribute'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'EReference'):\n",
    "            p[1] = p[1] + 1\n",
    "    p = np.array(p)\n",
    "    if (np.sum(p) != 0):\n",
    "        ps.append(p/np.sum(p))\n",
    "    else:\n",
    "        ps.append(p)\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/np.min(np.mean(ps, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOpposite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Reference(EClass c):EReference ->\n",
    "    eOpposite := if (UniformBool(a)) ReferenceOpp(self.EType as EClass,self,c)\n",
    "  ; \n",
    "```\n",
    "\n",
    "Estimating `a` by calculating the proportion of references that contain an opposite one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposite= []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EReference':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eOpposite'):\n",
    "                        cont = cont + 1\n",
    "                opposite.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([n for n in opposite if n == 1])/len(opposite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIATRA and ALLOY, estimating the scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For VIATRA and ALLOY, the distribution over the objects (i.e., $P(o)$) needs to be approximated. First, we calculate $\\{o_1,\\dots,o_n\\}$ by counting the number of objects of each model in $R_{II}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.arange(0, 500, 5)\n",
    "numberObjects = [len([n for n in G]) for G in Gs]\n",
    "hist = plt.hist(numberObjects, bins = bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the KDE function:\n",
    "\n",
    "$$\\hat{f}_{h,K}(o)=\\frac{1}{nh}\\sum_{i=1}^nK\\left(\\frac{o-o_i}{h}\\right).$$\n",
    "\n",
    "Where $K \\in \\{\\text{gaussian, tophat}\\}$ and $h\\in \\texttt{np.logspace(-2, -1, 20)}$. $K$ and $h$ are fixed using crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "numberObjects = [[len([n for n in G])] for G in Gs]\n",
    "\n",
    "params = {'bandwidth': np.logspace(-2, -1, 20),\n",
    "         'kernel':['gaussian', 'tophat']}\n",
    "grid = GridSearchCV(KernelDensity(), params)\n",
    "grid.fit(np.array(numberObjects))\n",
    "print(\"best bandwidth: {0}\".format(grid.best_estimator_.bandwidth))\n",
    "print(\"best kernel: {0}\".format(grid.best_estimator_.kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For VIATRA we sample 300 from $\\hat{f}_{h,K}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kde = grid.best_estimator_\n",
    "new_data = kde.sample(300, random_state=0)\n",
    "new_data = new_data.reshape(-1)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the histogram samples are close to the original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_bin=5\n",
    "bins = np.arange(-100, 500, size_bin)\n",
    "numberObjects = [len([n for n in G]) for G in Gs]\n",
    "hist = plt.hist(numberObjects, bins = bins, alpha=0.5,density=True)\n",
    "plt.hist(new_data, bins = bins, alpha=0.5,density=True)\n",
    "probs = hist[0]\n",
    "probs = (probs/np.sum(probs))\n",
    "objs = hist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the config files for VIATRA and ALLOY. These files are already provided together with the final and generated models. Therefore, you should not execute these code snippets. \n",
    "\n",
    "**Note**: For Alloy we generate more samples (400) since the generator fails more when it looks for a solution to the logic problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import random\n",
    "i = 0\n",
    "for s in new_data:\n",
    "    with open('../configurationFiles/Ecore/model.vsconfig', 'r') as file:\n",
    "        data = file.read()\n",
    "    x = data.replace(\"#node += 12..12\", \"#node += \"+str(int(s)))\n",
    "    x = x.replace(\"debug =\\t\\t\\t\\\"outputs/debug\\\"\",\"debug =\\t\\t\\t\\\"outputs\"+str(i)+\"/debug\\\"\")\n",
    "    x = x.replace(\"log =\\t\\t\\t\\\"outputs/log.txt\\\"\",\"log =\\t\\t\\t\\\"outputs\"+str(i)+\"/log.txt\\\"\")\n",
    "    x = x.replace(\"output =\\t\\t\\\"outputs/models\\\"\",\"output =\\t\\t\\\"outputs\"+str(i)+\"/models\\\"\")\n",
    "    x = x.replace(\"runs = 400\",\"runs = 1\")\n",
    "    with open(\"../configurationFiles/Ecore/VIATRA/smallEcoreGen\"+str(i)+\".vsconfig\", \"w\") as text_file:\n",
    "        text_file.write(x)\n",
    "        i = i + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "new_data = kde.sample(400, random_state=0)\n",
    "new_data = new_data.reshape(-1)\n",
    "new_data\n",
    "i = 0\n",
    "for s in new_data:\n",
    "    if int(s)>30:\n",
    "        print(s)\n",
    "        continue\n",
    "    with open('../configurationFiles/Ecore/modelAlloy.vsconfig', 'r') as file:\n",
    "        data = file.read()\n",
    "    x = data.replace(\"#node += 12..12\", \"#node += \"+str(int(s)))\n",
    "    x = x.replace(\"debug =\\t\\t\\t\\\"outputs/debug\\\"\",\"debug =\\t\\t\\t\\\"outputs\"+str(i)+\"/debug\\\"\")\n",
    "    x = x.replace(\"log =\\t\\t\\t\\\"outputs/log.txt\\\"\",\"log =\\t\\t\\t\\\"outputs\"+str(i)+\"/log.txt\\\"\")\n",
    "    x = x.replace(\"output =\\t\\t\\\"outputs/models\\\"\",\"output =\\t\\t\\\"outputs\"+str(i)+\"/models\\\"\")\n",
    "    x = x.replace(\"ViatraSolver\", \"AlloySolver\")\n",
    "    with open(\"../configurationFiles/Ecore/ALLOY/smallEcoreGen\"+str(i)+\".vsconfig\", \"w\") as text_file:\n",
    "        text_file.write(x)\n",
    "        i = i + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do thy same as the previous section but considering pairs $(o,d)$ where $o$ is the number of objects and $d$ is the average out degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_objects = [np.mean([G.out_degree(n) for n in G]) for G in Gs]\n",
    "objects_deg = np.array(list(zip(numberObjects,deg_objects)))\n",
    "objects_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'bandwidth': np.logspace(-2, -1, 20),\n",
    "         'kernel':['gaussian', 'tophat']}\n",
    "grid2 = GridSearchCV(KernelDensity(), params)\n",
    "grid2.fit(objects_deg)\n",
    "print(\"best bandwidth: {0}\".format(grid2.best_estimator_.bandwidth))\n",
    "print(\"best kernel: {0}\".format(grid2.best_estimator_.kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde2 = grid2.best_estimator_\n",
    "new_data2 = kde2.sample(300, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the new data generated (i.e., new pairs $(o,d)$), we call the RANDOM generator in order to generate the models. Doing something like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import random\n",
    "import subprocess\n",
    "i = 0\n",
    "for s in new_data2:\n",
    "    subprocess.call(['java', '-jar', 'path to jar of the generator', \n",
    "                     '-m','path to metamodel',\n",
    "                    '-f','-n','1','-s',str(s[0]),'-d',str(s[1]),'-o',\n",
    "                     'path to output folder',\n",
    "                    '-e',str(i)])\n",
    "    i = i + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated models used to report the results in the paper are already provided."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
